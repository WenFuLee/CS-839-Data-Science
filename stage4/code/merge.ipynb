{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import py_entitymatching as em\n",
    "import numpy as np\n",
    "\n",
    "datasets_dir = os.getcwd() + os.sep\n",
    "\n",
    "pathA = datasets_dir + \"/data/imdb_clean.csv\"\n",
    "pathB = datasets_dir + \"/data/tomato_clean.csv\"\n",
    "pathC = datasets_dir + \"/data/block.csv\"\n",
    "\n",
    "A = pd.read_csv(pathA)\n",
    "B = pd.read_csv(pathB)\n",
    "# Rename first empty attr \n",
    "# df.rename(columns={\"Unnamed: 0\": \"id\"},  inplace=True)\n",
    "\n",
    "p_A = A[['movie_no', 'movie_name', 'movie_year', 'movie_director', 'movie_star']]\n",
    "p_B = B[['movie_no', 'movie_name', 'movie_year', 'movie_director', 'movie_star']]\n",
    "\n",
    "em.set_key(p_A, 'movie_no')\n",
    "em.set_key(p_B, 'movie_no')\n",
    "\n",
    "pathS = datasets_dir + \"/data/labeled_data.csv\"\n",
    "\n",
    "S = em.read_csv_metadata(pathS, \n",
    "                         key='_id',\n",
    "                         ltable=p_A, rtable=p_B, \n",
    "                         fk_ltable='ltable_movie_no', fk_rtable='rtable_movie_no')\n",
    "\n",
    "IJ = em.split_train_test(S, train_proportion=0.7, random_state=0)\n",
    "I = IJ['train']\n",
    "J = IJ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifier\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature generation\n",
    "F = em.get_features_for_matching(p_A, p_B, validate_inferred_attr_types=False)\n",
    "\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='label',\n",
    "                            show_progress=False)\n",
    "\n",
    "# Missing value\n",
    "H = em.impute_table(H, \n",
    "                exclude_attrs=['_id', 'ltable_movie_no', 'rtable_movie_no', 'label'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Corss Validation \n",
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_movie_no', 'rtable_movie_no', 'label'],\n",
    "        k=5, # Num of fold\n",
    "        target_attr='label', metric_to_select_matcher='f1', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 98.18% (54/55)\n",
      "Recall : 96.43% (54/56)\n",
      "F1 : 97.3%\n",
      "False positives : 1 (out of 55 positive predictions)\n",
      "False negatives : 2 (out of 98 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Apply to testing set\n",
    "\n",
    "fc = result['selected_matcher'] # LinReg here\n",
    "# dt = em.DTMatcher(name='DT', random_state=0)\n",
    "\n",
    "fc.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_movie_no', 'rtable_movie_no', 'label'], \n",
    "       target_attr='label')\n",
    "\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='label', show_progress=False)\n",
    "\n",
    "predictions = fc.predict(table=L, exclude_attrs=['_id', 'ltable_movie_no', 'rtable_movie_no', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C is the blokced data \n",
    "C = em.read_csv_metadata(pathC,\n",
    "                        key='_id',\n",
    "                        ltable=p_A, rtable=p_B,\n",
    "                        fk_ltable='ltable_movie_no', fk_rtable='rtable_movie_no')\n",
    "\n",
    "cl = result['selected_matcher']\n",
    "\n",
    "L = em.extract_feature_vecs(C, feature_table=F,\n",
    "                            show_progress=False)\n",
    "\n",
    "\n",
    "predictions = cl.predict(table=L, exclude_attrs=['_id', 'ltable_movie_no', 'rtable_movie_no'], \n",
    "              append=True, target_attr='predicted', probs_attr='score', return_probs = True, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuple predicted as match\n",
    "tn = predictions[(predictions['predicted'] == 1)]\n",
    "# C[C['_id'].isin(tn['_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Duplicate detect\n",
    "dup_A = tn[tn[\"ltable_movie_no\"].duplicated(keep=False)]\n",
    "dup_B = tn[tn[\"rtable_movie_no\"].duplicated(keep=False)]\n",
    "# C[C['_id'].isin(dup_A['_id'])] \n",
    "# C[C['_id'].isin(dup_B['_id'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dup_T = pd.merge(dup_A, dup_B, how='outer', on=['_id','ltable_movie_no', 'rtable_movie_no'])\n",
    "# dup_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove duplicate\n",
    "# clean_dup_A = tn[\"ltable_movie_no\"].drop_duplicates(keep='first')\n",
    "# clean_dup_B = tn[\"rtable_movie_no\"].drop_duplicates(keep='first')\n",
    "clean_dup_A = tn[~(tn[\"ltable_movie_no\"].isin(dup_T['ltable_movie_no']))]\n",
    "clean_dup_B = tn[~(tn[\"rtable_movie_no\"].isin(dup_T['rtable_movie_no']))]\n",
    "# clean_dup_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove all matched from A and B (A' and B')\n",
    "new_A = A[(~A['movie_no'].isin(clean_dup_A['ltable_movie_no']))]\n",
    "new_B = B[(~B['movie_no'].isin(clean_dup_B['rtable_movie_no']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select one pair of duplicate pairs\n",
    "dict_A = {}\n",
    "dict_B = {}\n",
    "\n",
    "res = []\n",
    "s_A = []\n",
    "s_B = []\n",
    "for index, row in dup_T.iterrows():\n",
    "    if (row['ltable_movie_no'] not in dict_A) and (row['rtable_movie_no'] not in dict_B):\n",
    "        dict_A[row['ltable_movie_no']] = 1\n",
    "        dict_B[row['rtable_movie_no']] = 1\n",
    "        s_A.append(row['ltable_movie_no'])\n",
    "        s_B.append(row['rtable_movie_no'])\n",
    "        res.append(row['_id'])\n",
    "\n",
    "dict_RA = {}    \n",
    "dict_RB = {}\n",
    "for index, row in dup_T.iterrows():\n",
    "    if (row['ltable_movie_no'] not in dict_A):\n",
    "        dict_RA[row['ltable_movie_no']] = 1;\n",
    "    if (row['rtable_movie_no'] not in dict_B):\n",
    "        dict_RB[row['rtable_movie_no']] = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_RB\n",
    "rem_B = B[B['movie_no'].isin(dict_RB)]\n",
    "\n",
    "dict_RA\n",
    "rem_A = A[A['movie_no'].isin(dict_RA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_A = clean_dup_A['ltable_movie_no'].append(pd.Series(s_A))\n",
    "# s_B = clean_dup_B['rtable_movie_no'].append(pd.Series(s_B))\n",
    "# rem_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_A = A[(A['movie_no'].isin(clean_dup_A['ltable_movie_no']))]\n",
    "m_B = B[(B['movie_no'].isin(clean_dup_B['rtable_movie_no']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_dup_A.rename(columns={\"ltable_movie_no\": \"movie_no\"}, inplace = True)\n",
    "clean_dup_B.rename(columns={\"rtable_movie_no\": \"movie_no\"}, inplace = True)\n",
    "\n",
    "m_B = pd.merge(m_B, clean_dup_B[['_id', 'movie_no']], how = 'left', on = 'movie_no')\n",
    "m_A = pd.merge(m_A, clean_dup_A[['_id', 'movie_no']], how = 'left', on = 'movie_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_F = pd.merge(m_A[['_id','movie_no', 'movie_name', 'movie_year', 'movie_certificate', 'movie_runtime', \n",
    "                   'movie_genre', 'movie_score', 'movie_gross', 'movie_director', 'movie_star']],\n",
    "               m_B[['_id','movie_writer', 'tomatoter', 'audience']], how = 'left', on = '_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_Dl = tn[tn[\"_id\"].isin(res)]\n",
    "m_Dr = m_Dl.copy()\n",
    "m_Dl.rename(columns={\"ltable_movie_no\": \"movie_no\"}, inplace = True)\n",
    "m_Dr.rename(columns={\"rtable_movie_no\": \"movie_no\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_DA = A[(A['movie_no'].isin(s_A))]\n",
    "m_DB = B[(B['movie_no'].isin(s_B))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_DB = pd.merge(m_DB, m_Dr[['_id', 'movie_no']], how = 'left', on = 'movie_no')\n",
    "m_DA = pd.merge(m_DA, m_Dl[['_id', 'movie_no']], how = 'left', on = 'movie_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_DF = pd.merge(m_DA[['_id','movie_no', 'movie_name', 'movie_year', 'movie_certificate', 'movie_runtime', \n",
    "                   'movie_genre', 'movie_score', 'movie_gross', 'movie_director', 'movie_star']],\n",
    "               m_DB[['_id','movie_writer', 'tomatoter', 'audience']], how = 'left', on = '_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_A = new_A.drop(['Unnamed: 0', 'movie_no'], axis = 1)\n",
    "new_B = new_B.drop(['Unnamed: 0', 'movie_no'], axis = 1)\n",
    "rem_A = rem_A.drop(['Unnamed: 0', 'movie_no'], axis = 1)\n",
    "rem_B = rem_B.drop(['Unnamed: 0', 'movie_no'], axis = 1)\n",
    "m_F = m_F.drop(['_id', 'movie_no'], axis=1)\n",
    "m_DF = m_DF.drop(['_id', 'movie_no'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [new_A, rem_A, new_B, rem_B, m_F, m_DF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"merge_table.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
