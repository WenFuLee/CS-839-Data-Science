{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm, tree, ensemble, datasets\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "import pandas as pd\n",
    "import graphviz \n",
    "\n",
    "func_list = [tree.DecisionTreeClassifier, \\\n",
    "             ensemble.RandomForestClassifier, \\\n",
    "             svm.SVC, \\\n",
    "             linear_model.LinearRegression, \\\n",
    "             linear_model.LogisticRegression]\n",
    "\n",
    "func_param = [{'max_depth':9}, \\\n",
    "              {}, \\\n",
    "              #{'max_depth':20, 'n_estimators':30, 'criterion':\"entropy\", 'max_features':None, 'min_samples_split':17}, \\\n",
    "              {'kernel':'rbf', 'C':2, 'gamma': 0.1}, \\\n",
    "              {}, \\\n",
    "              {'C':1e5}]\n",
    "\n",
    "folder_path = 'Documents/UW_Madison/Course/2nd_Semester/CS839/stage4/features/'\n",
    "\n",
    "def training(X, Y, cv_type):\n",
    "    best_F1 = 0;\n",
    "    best_classifier = []\n",
    "    best_idx = None\n",
    "    \n",
    "    for idx in [1]:\n",
    "    #for idx in [0, 1, 2, 3, 4]:\n",
    "        l = func_list[idx]\n",
    "        print(\"{}. {}\".format(idx, l.__name__))\n",
    "        \n",
    "        if cv_type == 0:\n",
    "            # Without Cross-Validation\n",
    "            classifier = l()\n",
    "            classifier.fit(X, Y)\n",
    "            Y_pred = classifier.predict(X)\n",
    "        elif cv_type == 1:\n",
    "            # With Cross-Validation\n",
    "            classifier = l(**func_param[idx])\n",
    "            Y_pred = cross_val_predict(classifier, X, Y, cv=5)\n",
    "            classifier.fit(X, Y)\n",
    "\n",
    "        print(\"best_param = {}\".format(classifier))\n",
    "        F1 = calPR(Y, Y_pred)\n",
    "        \n",
    "        if F1 > best_F1:\n",
    "            best_F1 = F1\n",
    "            best_classifier = classifier\n",
    "            best_idx = idx\n",
    "\n",
    "    return best_classifier, best_idx\n",
    "\n",
    "def pq_test(X, Y, cv_type, best_idx):\n",
    "    l = func_list[best_idx]\n",
    "    print(\"{}. {}\".format(best_idx, l.__name__))\n",
    "\n",
    "    if cv_type == 0:\n",
    "        # Without Cross-Validation\n",
    "        classifier = l()\n",
    "        classifier.fit(X, Y)\n",
    "        Y_pred = classifier.predict(X)\n",
    "    elif cv_type == 1:\n",
    "        # With Cross-Validation\n",
    "        classifier = l(**func_param[best_idx])\n",
    "        Y_pred = cross_val_predict(classifier, X, Y, cv=2)\n",
    "        classifier.fit(X, Y)\n",
    "        \n",
    "    print(\"best_param = {}\".format(classifier))\n",
    "    print(\"[Before rule-based postprocessing step]\")\n",
    "    calPR(Y, Y_pred)\n",
    "\n",
    "    #saveAnalysis(Y, Y_pred, \"_pq\", 0)\n",
    "    \n",
    "    # Rule-based postprocessing step\n",
    "    print(\"[After rule-based postprocessing step]\")\n",
    "    Y_pred_new = post_processing(Y_pred, 0)\n",
    "    calPR(Y, Y_pred_new)\n",
    "    \n",
    "    saveAnalysis(Y, Y_pred_new, \"_pq\", 0)\n",
    "    \n",
    "def saveAnalysis(Y, Y_pred, special_name, train_type):\n",
    "    if train_type == 0:\n",
    "        df = pd.read_csv(folder_path + 'train_index.csv')\n",
    "    else:\n",
    "        df = pd.read_csv(folder_path + 'test_index.csv')  \n",
    "    train_index = df.values\n",
    "    df = pd.read_csv(folder_path + 'X_train.csv')\n",
    "    feature_title = list(df)\n",
    "    \n",
    "    # Check false negative to increase R\n",
    "    print(\"False Negative generating...\")\n",
    "    \n",
    "    false_neg_list = []\n",
    "    false_neg = []    \n",
    "    false_neg.append(\"[doc name]\")\n",
    "    for d in feature_title:\n",
    "        false_neg.append(d)\n",
    "    false_neg_list.append(false_neg)\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == 1 and Y_pred[i] != 1:\n",
    "            false_neg = []\n",
    "            false_neg.append(train_index[i])\n",
    "            for x in X[i]:\n",
    "                false_neg.append(x)\n",
    "            false_neg_list.append(false_neg)\n",
    "    df = pd.DataFrame(false_neg_list)\n",
    "    df.to_csv(folder_path + '/false_neg' + special_name + '.csv')\n",
    "    \n",
    "    # Check false positive to increase P\n",
    "    print(\"False Positive generating...\\n\")\n",
    "    \n",
    "    false_pos_list = []\n",
    "    false_pos = []    \n",
    "    false_pos.append(\"[doc name]\")\n",
    "    for d in feature_title:\n",
    "        false_pos.append(d)\n",
    "    false_pos_list.append(false_pos)\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] != 1 and Y_pred[i] == 1:\n",
    "            false_pos = []\n",
    "            false_pos.append(train_index[i])\n",
    "            for x in X[i]:\n",
    "                false_pos.append(x)\n",
    "            false_pos_list.append(false_pos)\n",
    "    df = pd.DataFrame(false_pos_list)\n",
    "    df.to_csv(folder_path + '/false_pos' + special_name + '.csv')\n",
    "    \n",
    "def calPR(Y, Y_pred):\n",
    "    true_pred_num = 0\n",
    "    total_pos_label_num = 0\n",
    "    pred_pos_label_num = 0\n",
    "    for i in range(len(Y)):\n",
    "        if Y_pred[i] >= 0.5:\n",
    "            Y_pred[i] = 1\n",
    "        else:\n",
    "            Y_pred[i] = 0\n",
    "\n",
    "        if Y[i] == 1 and Y_pred[i] == 1:\n",
    "            true_pred_num = true_pred_num + 1\n",
    "        if Y[i] == 1:\n",
    "            total_pos_label_num = total_pos_label_num + 1\n",
    "        if Y_pred[i] == 1:\n",
    "            pred_pos_label_num = pred_pos_label_num + 1\n",
    "\n",
    "    assert (true_pred_num > 0),\"true_pred_num = 0!\"\n",
    "    assert (pred_pos_label_num > 0),\"pred_pos_label_num = 0!\"\n",
    "    P = float(true_pred_num)/pred_pos_label_num\n",
    "    assert (total_pos_label_num > 0),\"total_pos_label_num = 0!\"\n",
    "    R = float(true_pred_num)/total_pos_label_num\n",
    "    F1 = (2 * P * R)/(P + R)\n",
    "    \n",
    "    print(\"- Precision(P) = {}/{} = {:.6f}\".format(true_pred_num, pred_pos_label_num, P)) \n",
    "    print(\"- Recall(R) = {}/{} = {:.6f}\".format(true_pred_num, total_pos_label_num, R)) \n",
    "    print(\"- F1 = {:.6f}\\n\".format(F1))\n",
    "    \n",
    "    return F1\n",
    "\n",
    "def testing(best_classifier):\n",
    "    print(\"{}. {}\".format(best_idx, func_list[best_idx].__name__))\n",
    "    print(\"best_param = {}\".format(best_classifier))\n",
    "    \n",
    "    df = pd.read_csv(folder_path + '/X_test.csv')\n",
    "    X_test = df.values\n",
    "    df = pd.read_csv(folder_path + '/y_test.csv')\n",
    "    Y_test = df.values\n",
    "    \n",
    "    print(\"[Before rule-based postprocessing step]\")\n",
    "    Y_pred = best_classifier.predict(X_test)\n",
    "    calPR(Y_test, Y_pred)\n",
    "    \n",
    "    #saveAnalysis(Y_test, Y_pred, \"_test\", 1)\n",
    "    \n",
    "    # Rule-based postprocessing step\n",
    "    print(\"[After rule-based postprocessing step]\")\n",
    "    Y_pred_new = post_processing(Y_pred, 1)\n",
    "    calPR(Y_test, Y_pred_new)\n",
    "    \n",
    "    saveAnalysis(Y_test, Y_pred_new, \"_test\", 1)\n",
    "    \n",
    "# post processing\n",
    "def post_processing(y_test_pred, train_type):\n",
    "    # removing words in prefix dict\n",
    "    input_file = open(folder_path + 'prefix_dict.txt', 'rb')\n",
    "    lines = input_file.read().lower().splitlines()\n",
    "    prefix_dict = list(set([ l.strip().lower() for l in lines ]))\n",
    "    input_file.close()\n",
    "\n",
    "    if train_type == 0:\n",
    "        doc = pd.read_csv(folder_path + 'train_index.csv')\n",
    "    else:\n",
    "        doc = pd.read_csv(folder_path + 'test_index.csv')\n",
    "\n",
    "    all_strings = doc.candidate_str.values\n",
    "    y_test_pred_new = np.zeros(len(y_test_pred))\n",
    "    for i, one_y in enumerate(y_test_pred):\n",
    "        y_test_pred_new[i] = one_y\n",
    "        if one_y == 1:\n",
    "            myStr = all_strings[i]\n",
    "            if myStr.isupper():\n",
    "                y_test_pred_new[i] = 0\n",
    "                continue\n",
    "\n",
    "            elif len(myStr) == 1:\n",
    "                y_val_pred_new[i] = 0\n",
    "                continue\n",
    "\n",
    "            for w in prefix_dict:\n",
    "                if w in myStr.lower().split():\n",
    "                    y_test_pred_new[i] = 0\n",
    "                    break\n",
    "\n",
    "    # remove words that contains country names\n",
    "    country_name = pd.read_csv(folder_path + 'country_name.csv')\n",
    "    all_names = country_name.Name.values\n",
    "    for i in range(len(y_test_pred)):\n",
    "        if y_test_pred_new[i] == 1:\n",
    "            for cname in all_names:\n",
    "                cname = cname.replace('\"', '')\n",
    "                if cname.lower() in all_strings[i].lower().split():\n",
    "                    y_test_pred_new[i] = 0\n",
    "                    break\n",
    "\n",
    "    # add words in celebrity names\n",
    "    input_file = open(folder_path + 'celebrity.txt', 'rb')\n",
    "    celeb_names = input_file.read().lower().splitlines()\n",
    "\n",
    "    for i in range(len(y_test_pred)):\n",
    "        if y_test_pred_new[i] == 0:\n",
    "            for cname in celeb_names:\n",
    "                if all_strings[i].lower() == cname.lower():\n",
    "                    y_test_pred_new[i] = 1\n",
    "                    break\n",
    "    \n",
    "    return y_test_pred_new\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parse data\n",
    "    df = pd.read_csv(folder_path + '/X_train.csv')\n",
    "    X = df.values\n",
    "    df = pd.read_csv(folder_path + '/y_train.csv')\n",
    "    #Y = df.values\n",
    "    Y = np.ravel(df.values)\n",
    "    cv_type = 1\n",
    "\n",
    "    # Training\n",
    "    print(\"\\n**************\")\n",
    "    print(\"** Training **\")\n",
    "    print(\"**************\\n\")\n",
    "\n",
    "    best_classifier, best_idx = training(X, Y, cv_type)\n",
    "\n",
    "    print(\"=======================================\")\n",
    "\n",
    "    # P/Q Test\n",
    "    print(\"\\n**************\")\n",
    "    print(\"** P/Q Test **\")\n",
    "    print(\"**************\\n\")\n",
    "\n",
    "    pq_test(X, Y, cv_type, best_idx)\n",
    "\n",
    "    print(\"=======================================\")\n",
    "\n",
    "    # Testing\n",
    "    print(\"\\n**************\")\n",
    "    print(\"** Testing **\")\n",
    "    print(\"**************\\n\")\n",
    "\n",
    "    testing(best_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
